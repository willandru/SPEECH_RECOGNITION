HACER TUTORIALES:
#1 DATA ADQUISITION AMD GIT STORAGING
#2 Audio proccesing with Python 
#3 DNN, CNN, RNN
#4 Speech Recognition:Boundary detection, vowel alignment, segmentation, windowing.

			TURTORIAL 1

DATA ADQUISITION AND GIT STORAGE:

OBJECTIVES: - Get familiar with audio data.
           - Get familiar with git.
           - Understand the real complexity of taking data(lots of data) to train a Neural Network, to motivate the search for seeking segmentation algorithms and finding new strategies to collect and label data.
           
           
DATA TO BE COLLECTED: a/ e/ i/ o/ u/ /(la,le,li,lo,lu) /(pa, pe, pi, po, pu) /(ar, er, ir, or, ur)
	Explicacion: Vamos a aprender a reconocer las vocales de una oracion completa, para identificar el timepo en que se pronuncian estas vocales, de esta manera vamos a alinear las silabas para extraer el sonido de las consonantes.
	Se han escogido 3 letras, L, P,R. Con ellas buscamos alinear las vocales y segmentar la silaba de la letra para poder tener un set de entrenamiento con los FONEMAS de cada letra.
	Las letras escogidas permiten formar el nombre del robot "Peper"
           
STEPS:
	-Download the app (choosen)
	- Take samples of vowels and two letter syllabes 
	- Try to collect data in a natural way. Don't worry for the background noise in fact it is usefull to add some variation to the data. Use different entonations, change your moood, elevate your voice,use differents hours of the day, decrease your voice, elongate the sounds and also strike them, in order to capture enough data repressentative of all the possible variations we need orders of thousands of data. To give you a number 10.000 samples yould be enough to see a statistical significative response. thopudg the number of data can be much more higger or lower, I dont know. Thats why, we are gonna try at least to collect 1.000 samples of a single syllabe per person. 
	- Git clone speech-recognition-and-processing
	- git status : verificamos la rama actual en la que estamos
	- git checkout data
	- cd/DATA/VOWELS
	- Once you've collected some audios of the fisrt vowel or syllabe, please find a way to rename all the files in the following format  "A_WG_1.a4m" "LA_WG_2.a4m" .
	- PLace the samples taken EVERY DAY in the right folder.
	- Push your data collected every day.
	

	Tutorial 2

	-- Look at the jupyter notebook

	TUTORIAL 3

	-The idea is to create a neural network that can learn and recognize the pattern of the 5 spanish vowels sound.

	- The neural network must be trained in a supervised way using the dataset VOWELS that we are collecting.

	The VOWEL data set contains the actual phonems of the spanish vowels. We want to learn to recognize the patterns that makes each vowel to be able to spot them latter in future words.

	So as you have seen the sound is a 1-D vector, data points taken at a specific frecuency in a fixed length of time, nontheless we can transform this vector to create a 3D image representation of the sound. It represents a secuecial set of points (recurrent).


	We are going to investigate Deep Neural Networks or DNN, Convolutional Neural Networks or CNN and Recurrent Neural Networks or RNN. 

	DNN

	They represent the typical architecture of a neural network, linear perceptrons ordered by input layer, hidden layers and output layer, we can make fully-connected layers or partially connected ones. We can use them to explore the fundamentals of neural networks

	CNN

	A very important architecture for analysing images the can be used for medical diagnostics, computer vision and anything related with an images, so it is of our interes to explore these architecture for speech recognition.

	RNN

	Recurrent neural networks, they suffer the problem of not been able to parallization therefore its trainig takes longer. THis is because of the nature of the neural architecture where a single perceptron takes the sequential input and retroaliments to itself and then passes ists output to the next perceptron secuentially. So these architecture has allowed us to model time-series data like speech very efectivelly.


	TUTORIAL 4


			VOWEL RECOGNITION NEURAL NETWORK USED FOR ALIGNING TEXT TO SPEECH  AND SEGMENTATION OF PHONEMS FROM SYLLABES TO ATUOMATICALLY CREATE A DATASET OF SPANISH PHONEMS.

	Abstract.

	By creating a dataset of vowel phonems collected by our selfs or found in the internet we want to create a simple neural network architecture than can recognize the pattern of a vowel.The architecture would be succsesfull if given an audio file with several words it can spot all the vowels correctlly. Once this is set up, we want to use this neural network to spot the vowels of syllabes containing the PHONEMS of the lleters of spanish, but we can also use it to try to label data from internet datasets in a phonem-based way. It means that we want to get a final dataset whit the phonems of the spanish language. 


DATASETS:

VOWEL-DATASET: is a dataset containing 5 folders each labeled with a vowel. These are the phonems of the spanish vowels.

SYLLABES-DATASET: It's a dataset containing as many folders as syllabes collected, the idea is to have all the possible phonems of the spanish language represented in those syllabes.

PHONEM-DATASET: Its a dataset containig the VOWEL-dataset and also has all the PHEMS of the LETTERS of the alphabet. It represents short fragments of audio with the phonems.

INTERNET-DATASETS: They allow neural networks to learn whole words and therefore the data needed to create an Automatic Speech REcognition (ASR) system is data-expensive and computing-expensive as well. It would be more useful to be able to segment these data into its phonems, to create a huge data set that can train a network to recognize the fundamenta unit of spanish speech. 


































       	
